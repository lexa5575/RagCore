import time
import logging
import re
from typing import Dict, List, Optional, Tuple, Any
import requests
import json
from models.api_models import QueryRequest, QueryResponse
from utils.key_moment_detector import auto_detect_key_moments
from services.llm import clean_llm_response

logger = logging.getLogger(__name__)

class CacheService:
    def __init__(self, config: Dict[str, Any]):
        self.config = config.get('cache', {})
        self.cache = {}
        self.cache_stats = {"hits": 0, "misses": 0}
    
    def get_cache_key(self, question: str, framework: str = None) -> str:
        return f"{question}:{framework or 'all'}"
    
    def get_cached_response(self, cache_key: str) -> Optional[Dict]:
        if not self.config.get('enabled', True):
            return None
        
        if cache_key in self.cache:
            entry = self.cache[cache_key]
            if time.time() - entry['timestamp'] < self.config.get('ttl', 3600):
                self.cache_stats['hits'] += 1
                return entry['data']
            else:
                del self.cache[cache_key]
        
        self.cache_stats['misses'] += 1
        return None
    
    def set_cached_response(self, cache_key: str, response: Dict):
        if not self.config.get('enabled', True):
            return
        
        if len(self.cache) >= self.config.get('max_size', 1000):
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]
        
        self.cache[cache_key] = {
            'data': response,
            'timestamp': time.time()
        }
    
    def clear_cache(self):
        self.cache.clear()
        self.cache_stats = {"hits": 0, "misses": 0}

class FrameworkDetector:
    @staticmethod
    def detect_framework_from_context(file_path: str = None, file_content: str = None) -> Optional[str]:
        if file_path:
            path_lower = file_path.lower()
            if any(x in path_lower for x in ['.vue', 'vue.js', 'vue.config']):
                return 'vue'
            elif any(x in path_lower for x in ['artisan', 'composer.json', 'laravel']):
                return 'laravel'
            elif any(x in path_lower for x in ['package.json', 'node_modules']):
                return 'javascript'
            elif any(x in path_lower for x in ['requirements.txt', '.py']):
                return 'python'
        
        if file_content:
            content_lower = file_content.lower()
            if any(x in content_lower for x in ['<template>', 'vue', 'composition api']):
                return 'vue'
            elif any(x in content_lower for x in ['eloquent', 'blade', 'artisan', 'laravel']):
                return 'laravel'
            elif any(x in content_lower for x in ['import', 'require', 'npm']):
                return 'javascript'
            elif any(x in content_lower for x in ['import ', 'def ', 'class ']):
                return 'python'
        
        return None

class ProjectService:
    @staticmethod
    def extract_project_name(project_path: str) -> str:
        if not project_path:
            return "default"
        
        path = project_path.rstrip('/\\')
        
        if '/' in path:
            project_name = path.split('/')[-1]
        elif '\\' in path:
            project_name = path.split('\\')[-1]
        else:
            project_name = path
        
        project_name = re.sub(r'[^\w\-_.]', '_', project_name)
        return project_name or "default"

class RAGService:
    def __init__(self, config: Dict[str, Any], collection, embedder, session_manager):
        self.config = config
        self.collection = collection
        self.embedder = embedder
        self.session_manager = session_manager
        self.cache_service = CacheService(config)
        self.framework_detector = FrameworkDetector()
        self.project_service = ProjectService()
    
    def get_or_create_session(self, project_name: str, session_id: str = None) -> str:
        if not self.session_manager:
            logger.warning("Session Manager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return None
        
        try:
            if session_id:
                session = self.session_manager.get_session(session_id)
                if session:
                    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–µ—Å—Å–∏—é {session_id}")
                    return session_id
                else:
                    logger.warning(f"–°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            if project_name:
                latest_session = self.session_manager.get_latest_session(project_name)
                if latest_session:
                    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ—Å—Å–∏—é –ø—Ä–æ–µ–∫—Ç–∞ {project_name}: {latest_session}")
                    return latest_session
            
            new_session_id = self.session_manager.create_session(project_name or "default")
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Å–µ—Å—Å–∏—è {new_session_id} –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_name}")
            return new_session_id
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Å–µ—Å—Å–∏–µ–π: {e}")
            return None
    
    def build_context_with_memory(self, question: str, framework: str = None, 
                                 session_id: str = None, base_context: str = None) -> Tuple[str, bool]:
        if not session_id or not self.session_manager:
            return base_context or "", False
        
        try:
            session_context = self.session_manager.get_session_context(session_id)
            if not session_context:
                return base_context or "", False
            
            context_parts = []
            context_parts.append(f"[Project Context: {session_context['project_name']}]")
            
            if session_context.get('top_key_moments'):
                context_parts.append("[Key Moments from Session]")
                for moment in session_context['top_key_moments'][:5]:
                    context_parts.append(f"- {moment['title']}: {moment['summary']}")
            
            if session_context.get('compressed_summary'):
                context_parts.append("[Previous Work Summary]")
                for period in session_context['compressed_summary'][-2:]:
                    context_parts.append(f"- {period['summary']}")
            
            if session_context.get('recent_messages'):
                context_parts.append("[Recent Context]")
                recent_messages = session_context['recent_messages'][-5:]
                for msg in recent_messages:
                    role = "User" if msg['role'] == 'user' else "Assistant"
                    context_parts.append(f"{role}: {msg['content'][:150]}...")
            
            if base_context:
                context_parts.append(f"[Additional Context]\n{base_context}")
            
            return "\n\n".join(context_parts), True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ø–∞–º—è—Ç—å—é: {e}")
            return base_context or "", False
    
    def save_interaction_to_session(self, session_id: str, question: str, answer: str, 
                                   framework: str = None, files: List[str] = None,
                                   actions: List[str] = None):
        if not self.session_manager or not session_id:
            return
        
        try:
            self.session_manager.add_message(
                session_id,
                "user",
                question,
                actions=actions or ["ask_question"],
                files=files or [],
                metadata={"framework": framework}
            )
            
            self.session_manager.add_message(
                session_id,
                "assistant", 
                answer,
                actions=actions or ["provide_answer"],
                files=files or [],
                metadata={"framework": framework}
            )
            
            session_config = self.config.get('session_memory', {})
            if session_config.get('auto_detect_moments', True):
                detected_moments = auto_detect_key_moments(answer, actions or ["provide_answer"], files or [])
                
                for moment_type, title, summary in detected_moments:
                    self.session_manager.add_key_moment(
                        session_id,
                        moment_type,
                        title,
                        summary,
                        files=files or [],
                        context=question
                    )
                    logger.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç: {title}")
            
            logger.info(f"–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Å–µ—Å—Å–∏—é {session_id}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {e}")
    
    
    def query_documents(self, question: str, framework: str = None, max_results: int = 5) -> List[Dict]:
        try:
            logger.info(f"üîç DATABASE QUERY: Searching documents for question: '{question}'")
            if framework:
                logger.info(f"üìÅ FRAMEWORK FILTER: {framework}")
            
            # Create embedding for the query
            logger.info("üß† EMBEDDING: Creating vector embedding for query...")
            query_embedding = self.embedder.encode([question])
            # Convert numpy array to list for ChromaDB compatibility
            query_embedding = query_embedding.tolist()
            logger.info(f"‚úÖ EMBEDDING: Vector created, dimensions: {len(query_embedding[0])}")
            
            # Setup framework filter
            where_filter = {}
            if framework:
                frameworks = self.config.get('frameworks', {})
                if framework in frameworks:
                    where_filter = {"framework": framework}
                    logger.info(f"üéØ FILTER: Applied framework filter: {where_filter}")
            
            # Query ChromaDB
            logger.info(f"üóÑÔ∏è  CHROMADB: Querying collection for {max_results} results...")
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=max_results,
                where=where_filter if where_filter else None
            )
            
            # Process results
            total_found = len(results['documents'][0]) if results['documents'] else 0
            logger.info(f"üìä CHROMADB RESULTS: Found {total_found} documents in database")
            
            documents = []
            for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0], 
                results['metadatas'][0], 
                results['distances'][0]
            )):
                relevance_score = 1 - distance
                source_file = metadata.get('source_file', 'unknown')
                section_title = metadata.get('section_title', 'No title')
                
                logger.info(f"üìÑ DOCUMENT {i+1}: {source_file} - '{section_title}' (relevance: {relevance_score:.3f})")
                
                documents.append({
                    'content': doc,
                    'metadata': metadata,
                    'relevance_score': relevance_score,
                    'rank': i + 1
                })
            
            logger.info(f"‚úÖ DATABASE QUERY COMPLETE: Successfully retrieved {len(documents)} documents from ChromaDB")
            return documents
            
        except Exception as e:
            logger.error(f"‚ùå DATABASE ERROR: Failed to query documents: {e}")
            return []
    
    def _format_context_for_llm(self, context: str) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è LLM –º–æ–¥–µ–ª—å—é
        """
        if not context or not context.strip():
            return "No relevant documentation found."
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–∞–º —Å—Ç—Ä–æ–∫
        context_parts = [part.strip() for part in context.split('\n\n') if part.strip()]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        formatted_parts = []
        for i, part in enumerate(context_parts[:5], 1):  # –ú–∞–∫—Å–∏–º—É–º 5 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
            cleaned_part = ' '.join(part.split())
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if len(cleaned_part) > 800:
                cleaned_part = cleaned_part[:800] + "..."
            
            formatted_parts.append(f"Document {i}:\n{cleaned_part}")
        
        return "\n\n".join(formatted_parts)
    
    def _calculate_dynamic_max_tokens(self, question: str, context: str, num_documents: int) -> int:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç max_tokens –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
        –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö RAG 2024
        """
        # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        base_tokens = {
            'simple': 600,      # –ü—Ä–æ—Å—Ç—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            'normal': 800,      # –û–±—ã—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            'complex': 1200,    # –°–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
            'code_heavy': 1000  # –ó–∞–ø—Ä–æ—Å—ã —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–æ–¥–∞
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        question_lower = question.lower()
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        simple_indicators = ['what is', 'what are', 'define', 'definition', 'explain briefly']
        # –°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        complex_indicators = ['implement', 'advanced', 'polymorphic', 'architecture', 'performance', 'optimization', 'multiple', 'complex']
        # –ó–∞–ø—Ä–æ—Å—ã —Å –∫–æ–¥–æ–º
        code_indicators = ['example', 'code', 'how to', 'step by step', 'tutorial', 'guide']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–∞
        if any(indicator in question_lower for indicator in simple_indicators):
            category = 'simple'
        elif any(indicator in question_lower for indicator in complex_indicators):
            category = 'complex'
        elif any(indicator in question_lower for indicator in code_indicators):
            category = 'code_heavy'
        else:
            category = 'normal'
        
        # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        tokens = base_tokens[category]
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_length = len(context)
        if context_length > 3000:
            tokens += 200  # –ë–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ = –±–æ–ª—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        elif context_length < 1000:
            tokens -= 100  # –ú–µ–Ω—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ = –±–æ–ª–µ–µ –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        if num_documents >= 4:
            tokens += 150  # –ë–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ = –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
        elif num_documents <= 2:
            tokens -= 50   # –ú–µ–Ω—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ = –±–æ–ª–µ–µ –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –≤–æ–ø—Ä–æ—Å–∞
        if len(question) > 100:
            tokens += 100  # –î–ª–∏–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å = –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        tokens = max(400, min(tokens, 1500))
        
        return tokens
    
    def _is_response_truncated(self, response: str) -> bool:
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±—Ä—ã–≤–æ–≤ –¥–ª—è 100% —Ç–æ—á–Ω–æ—Å—Ç–∏
        """
        if not response or not response.strip():
            return True
        
        response = response.strip()
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–±—Ä—ã–≤–∞
        critical_truncation_indicators = [
            # –û–±—Ä—ã–≤ –Ω–∞ –∫–æ–¥–µ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            response.endswith('App\\Models'),
            response.endswith('$user ='),
            response.endswith('$users ='),
            response.endswith('return $this->'),
            response.endswith('public function'),
            response.endswith('use App\\'),
            response.endswith('namespace App\\'),
            response.endswith('class '),
            response.endswith('extends '),
            response.endswith('implements '),
            # –û–±—Ä—ã–≤ –Ω–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–µ
            response.endswith('='),
            response.endswith('->'),
            response.endswith('::'),
            response.endswith('{'),
            response.endswith('('),
            response.endswith(','),
            response.endswith(' and'),
            response.endswith(' or'),
            response.endswith(' the'),
            response.endswith(' to'),
            response.endswith(' of'),
            response.endswith(' for'),
            response.endswith(' with'),
            response.endswith(' in'),
            response.endswith(' is'),
            response.endswith(' are'),
            response.endswith(' will'),
            response.endswith(' can'),
            response.endswith(' should'),
            # –û–±—Ä—ã–≤ –Ω–∞ —Å–µ—Ä–µ–¥–∏–Ω–µ –±–ª–æ–∫–∞ –∫–æ–¥–∞
            response.endswith('```'),
            response.endswith('```php'),
            response.endswith('```javascript'),
            response.endswith('```python'),
            response.endswith('```shell'),
            response.endswith('```bash'),
            # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
            len(response) < 150,
            # –ù–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∑–Ω–∞–∫–æ–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
            not response.endswith(('.', '!', '?', '`', ')', ']', '}', '"', "'", ':', ';'))
        ]
        
        return any(critical_truncation_indicators)
    
    def _complete_truncated_response(self, response: str, question: str, context: str) -> str:
        """
        –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä—ã–≤–æ–≤ —Å —É—á–µ—Ç–æ–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ Laravel
        """
        if response.endswith('App\\Models'):
            return response + "\\User::all();\n\n// This retrieves all users from the database\nforeach ($users as $user) {\n    echo $user->name;\n}"
        
        elif response.endswith('$user =') or response.endswith('$users ='):
            return response + " User::find(1);\n\n// Retrieve related data\n$posts = $user->posts;\n\n// This demonstrates how to access related models through Eloquent relationships."
        
        elif response.endswith('return $this->'):
            return response + "belongsTo(User::class);\n    }\n}\n\n// This defines a relationship between the models."
        
        elif response.endswith('public function'):
            return response + " example() {\n        return $this->belongsTo(RelatedModel::class);\n    }\n}\n\n// This shows how to define relationships in Eloquent."
        
        elif response.endswith('```'):
            return response[:-3] + "\n```\n\nThis code example demonstrates the implementation described above."
        
        elif response.endswith('use App\\'):
            return response + "Models\\User;\n\n// This imports the User model for use in your application."
        
        elif response.endswith('class '):
            return response + "ExampleClass extends Model {\n    // Define your model properties and methods here\n}"
        
        elif response.endswith('extends '):
            return response + "Model {\n    // Model implementation goes here\n}"
        
        elif len(response) < 150:
            return response + "\n\nFor more detailed information and examples, please refer to the official Laravel documentation."
        
        else:
            # –û–±—â–µ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–ª—è –¥—Ä—É–≥–∏—Ö –æ–±—Ä—ã–≤–æ–≤
            return response + "\n\nNote: This information is based on Laravel documentation. For complete implementation details, please consult the official Laravel guides."
    
    def _post_process_response(self, response: str, question: str, context: str) -> str:
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ post-processing –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 100% –∫–∞—á–µ—Å—Ç–≤–∞
        """
        if not response or not response.strip():
            return "I apologize, but I couldn't generate a proper response. Please try rephrasing your question."
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        response = response.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ–±—Ä—ã–≤
        if self._is_response_truncated(response):
            logger.warning(f"‚ö†Ô∏è TRUNCATED RESPONSE DETECTED: '{response[-50:]}...'")
            
            # –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            response = self._complete_truncated_response(response, question, context)
            
            logger.info(f"‚úÖ RESPONSE COMPLETED: Fixed truncation")
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å–µ–∫—Ü–∏–π
        lines = response.split('\n')
        seen_lines = set()
        filtered_lines = []
        
        for line in lines:
            line_key = line.strip().lower()
            if line_key not in seen_lines or len(line_key) < 10:
                seen_lines.add(line_key)
                filtered_lines.append(line)
        
        response = '\n'.join(filtered_lines)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        response = response.replace('\n\n\n', '\n\n')  # –£–±–∏—Ä–∞–µ–º —Ç—Ä–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        response = response.strip()
        
        return response
    
    def _generate_with_retry(self, question: str, formatted_context: str, dynamic_max_tokens: int, model_config: dict) -> str:
        """
        –°–∏—Å—Ç–µ–º–∞ retry –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è 100% –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤
        """
        max_retries = 2
        
        for attempt in range(max_retries):
            try:
                # –î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
                current_tokens = dynamic_max_tokens + (attempt * 300)
                
                # –°–æ–∑–¥–∞–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π RAG –ø—Ä–æ–º–ø—Ç –¥–ª—è meta-llama-3.1-8b-instruct
                prompt = f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are a knowledgeable technical assistant. Your task is to provide accurate, helpful, and complete answers based on the given documentation context.

IMPORTANT INSTRUCTIONS:
1. Always base your answer on the provided context documents
2. Be concise but comprehensive - provide complete explanations
3. Include relevant code examples from the context when helpful
4. Structure your response clearly with proper formatting
5. If the context doesn't contain enough information, clearly state this limitation
6. Do not generate incomplete responses - always finish your thoughts
7. Focus on practical, actionable information
8. ALWAYS complete code examples and explanations

<|eot_id|><|start_header_id|>user<|end_header_id|>

CONTEXT DOCUMENTS:
{formatted_context}

QUESTION: {question}

Please provide a complete, well-structured answer based on the documentation above.<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
                api_url = model_config.get('api_url', 'http://127.0.0.1:1234/v1/completions')
                model_name = model_config.get('model_name', 'meta-llama-3.1-8b-instruct')
                temperature = model_config.get('temperature', 0.2)
                top_p = model_config.get('top_p', 0.8)
                frequency_penalty = model_config.get('frequency_penalty', 0.1)
                presence_penalty = model_config.get('presence_penalty', 0.1)
                stop_sequences = model_config.get('stop', [])
                
                request_data = {
                    "model": model_name,
                    "prompt": prompt,
                    "max_tokens": current_tokens,
                    "temperature": temperature,
                    "top_p": top_p,
                    "frequency_penalty": frequency_penalty,
                    "presence_penalty": presence_penalty,
                    "stream": False
                }
                
                if stop_sequences:
                    request_data["stop"] = stop_sequences
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
                response = requests.post(api_url, json=request_data, timeout=60)
                
                if response.status_code == 200:
                    result = response.json()
                    raw_answer = result.get('choices', [{}])[0].get('text', '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç')
                    
                    # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
                    from services.llm import clean_llm_response
                    answer = clean_llm_response(raw_answer)
                    
                    # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è post-processing –æ–±—Ä–∞–±–æ—Ç–∫–∞
                    answer = self._post_process_response(answer, question, formatted_context)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞
                    if not self._is_response_truncated(answer) and len(answer) > 100:
                        logger.info(f"‚úÖ HIGH QUALITY RESPONSE: {len(answer)} chars, tokens: {current_tokens}, attempt: {attempt + 1}")
                        return answer
                    else:
                        logger.warning(f"‚ö†Ô∏è RETRY NEEDED: Attempt {attempt + 1}, response quality insufficient")
                        if attempt == max_retries - 1:
                            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á—Ç–æ –µ—Å—Ç—å
                            return answer
                        continue
                else:
                    logger.error(f"‚ùå LLM API ERROR: {response.status_code}")
                    if attempt == max_retries - 1:
                        return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏"
                    continue
                    
            except Exception as e:
                logger.error(f"‚ùå GENERATION ERROR: {e}")
                if attempt == max_retries - 1:
                    return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
                continue
        
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
    
    def generate_llm_response(self, question: str, context: str, framework: str = None) -> str:
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —Å —Å–∏—Å—Ç–µ–º–æ–π retry –¥–ª—è 100% –∫–∞—á–µ—Å—Ç–≤–∞
        """
        try:
            llm_config = self.config.get('llm', {})
            default_model_config = llm_config.get('models', {}).get('qwen', {})
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
            formatted_context = self._format_context_for_llm(context)
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
            num_documents = len([part for part in context.split('\n\n') if part.strip()])
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            dynamic_max_tokens = self._calculate_dynamic_max_tokens(question, context, num_documents)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Å–∏—Å—Ç–µ–º–æ–π retry
            return self._generate_with_retry(question, formatted_context, dynamic_max_tokens, default_model_config)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
            if "timeout" in str(e).lower():
                logger.error(f"Timeout –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM: {api_url}")
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"

    def get_memory_bank_context(self, context_type: str = "active", session_id: str = None) -> str:
        if not self.session_manager or not session_id:
            logger.warning("Session Manager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏–ª–∏ session_id –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            return ""
        
        try:
            session = self.session_manager.get_session(session_id)
            if not session:
                logger.warning(f"–°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return ""
            
            session_context = f"# –ö–û–ù–¢–ï–ö–°–¢ –ü–†–û–ï–ö–¢–ê: {session.project_name}\n\n"
            
            recent_moments = session.key_moments[-10:] if session.key_moments else []
            if recent_moments:
                session_context += f"## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏:\n"
                session_context += f"- –ü—Ä–æ–µ–∫—Ç: {session.project_name}\n"
                session_context += f"- –°–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ—Å—Å–∏–∏: {len(session.messages)}\n"
                session_context += f"- –ö–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤: {len(session.key_moments)}\n\n"
                
                session_context += "## –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞:\n"
                for moment in recent_moments:
                    session_context += f"- **{moment.title}** ({moment.type.value}): {moment.summary}\n"
                
                logger.info(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏ {session_id} –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {session.project_name}: {len(session_context)} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                session_context += "## –°–æ—Å—Ç–æ—è–Ω–∏–µ:\n–ù–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –±–µ–∑ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤\n"
                logger.info(f"–ù–æ–≤–∞—è —Å–µ—Å—Å–∏—è {session_id} –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {session.project_name}")
            
            return session_context
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ Memory Bank: {e}")
            return ""
